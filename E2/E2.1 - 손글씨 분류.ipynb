{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vietnamese-object",
   "metadata": {},
   "source": [
    "# E2.1 - 손글씨 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-savage",
   "metadata": {},
   "source": [
    "### (1) 필요한 모듈 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mounted-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-sheffield",
   "metadata": {},
   "source": [
    "### (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "union-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-botswana",
   "metadata": {},
   "source": [
    "### (3) 데이터 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-lingerie",
   "metadata": {},
   "source": [
    "* Feature Data 지정하기\n",
    "* Label Data 지정하기\n",
    "* Target Names 출력해 보기\n",
    "* 데이터 Describe 해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "norwegian-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "# 데이터 이해하기 \n",
    "print(dir(digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "younger-arcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# target 이해하기  - label은 숫자 0부터 9까지 총 10개. \n",
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genetic-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label data 지정하기 \n",
    "digits_label = digits.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "front-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 지정하기 \n",
    "digits_data = digits.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "governmental-bryan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
     ]
    }
   ],
   "source": [
    "print(digits_data.shape) # data 는 1797 row에 64 columns. sample 은 총 1797개. feature 가 뭔지 살펴보자. \n",
    "print(digits.feature_names) # feature는 8*8 pixel 이미지 (0부터 시작해서 7까지)- each pixel represents a feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "european-fancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# digits data description \n",
    "digits.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-drama",
   "metadata": {},
   "source": [
    "### (4) train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "numerous-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test size = 20% \n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-terrorism",
   "metadata": {},
   "source": [
    "### (5) 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-breeding",
   "metadata": {},
   "source": [
    "아래와 같은 모델 사용해 보기\n",
    "* Decision Tree \n",
    "* Random Forest \n",
    "* SVM \n",
    "* SGD Classifier \n",
    "* Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-salem",
   "metadata": {},
   "source": [
    "### (5)(a) Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "blind-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# digits_dt 변수 만들어 주기 \n",
    "digits_dt = DecisionTreeClassifier(random_state=32)\n",
    "\n",
    "# model fitting\n",
    "digits_dt.fit(X_train, y_train)\n",
    "\n",
    "# y predict 만들어주기 \n",
    "y_pred_dt = digits_dt.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-killing",
   "metadata": {},
   "source": [
    "### (5)(b) Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assigned-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# digits_rf 변수 만들어 주기 \n",
    "digits_rf = RandomForestClassifier(random_state=32)\n",
    "\n",
    "# model fitting\n",
    "digits_rf.fit(X_train, y_train)\n",
    "\n",
    "# y predict 만들어주기 \n",
    "y_pred_rf = digits_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-cleaners",
   "metadata": {},
   "source": [
    "### (5)(c) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "professional-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# digits_svm 변수 만들어 주기 \n",
    "digits_svm = svm.SVC()\n",
    "\n",
    "# model fitting\n",
    "digits_svm.fit(X_train, y_train)\n",
    "\n",
    "# y predict 만들어주기 \n",
    "y_pred_svm = digits_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-request",
   "metadata": {},
   "source": [
    "### (5)(d) SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "chubby-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# digits_sgd 변수 만들어 주기 \n",
    "digits_sgd = SGDClassifier()\n",
    "\n",
    "# model fitting\n",
    "digits_sgd.fit(X_train, y_train)\n",
    "\n",
    "# y predict 만들어주기 \n",
    "y_pred_sgd = digits_sgd.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-coast",
   "metadata": {},
   "source": [
    "### (5)(e) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cutting-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# digits_lr 변수 만들어 주기. max_iter 을 붙이지 않았을때 에러가 나서 첨부했다. \n",
    "digits_lr = LogisticRegression(max_iter=5000) \n",
    "\n",
    "# model fitting\n",
    "digits_lr.fit(X_train, y_train)\n",
    "\n",
    "# y predict 만들어주기 \n",
    "y_pred_lr = digits_lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-automation",
   "metadata": {},
   "source": [
    "### (6) 모델을 평가해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-mumbai",
   "metadata": {},
   "source": [
    "1. classification report 를 사용하면 accuracy score 뿐만 아니라 0부터 9까지의 각 아웃풋의 precision, recall, f1-score를 볼 수 있다. 이 방식을 사용한 이유는 0부터 9까지의 precision, recall, f1 score를 검토하고 낮은 숫자를 찾아내서 이유를 분석하기 위해서이다. \n",
    "2. 모델별 accuracy score 는 다음과 같다. \n",
    "    a) decision tree: 84%\n",
    "    b) random forest: 98%\n",
    "    c) svm: 98%\n",
    "    d) sgd: 96%\n",
    "    e) logistic regression: 97%  \n",
    "3. accuracy score를 기준으로 random forest 와 svm이 98%로 가장 높은 정확도를 보여준다. 하지만 logistic regression 도 97%, sgd 도 96% 로 크게 차이 나이 않는다. \n",
    "4. 그러므로 다른 test data 로 모델을 다시 평가해서 적합한 모델을 결정하는것도 고려해 볼만 하다. \n",
    "5. 아래 결과에서 한가지 눈에 띄는 점은 숫자 8의 precision, recall, f1 score가 다른 숫자들에 비해서 낮다. 왜 이런 결과 값이 나왔는지 조금 더 분석해 볼 필요가 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "incorporated-shade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        31\n",
      "           1       0.82      0.82      0.82        38\n",
      "           2       0.72      0.87      0.79        38\n",
      "           3       0.85      0.81      0.83        27\n",
      "           4       0.97      0.78      0.86        41\n",
      "           5       0.82      0.89      0.85        35\n",
      "           6       0.85      0.89      0.87        38\n",
      "           7       0.91      0.91      0.91        34\n",
      "           8       0.74      0.74      0.74        35\n",
      "           9       0.83      0.79      0.81        43\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.85      0.84      0.84       360\n",
      "weighted avg       0.85      0.84      0.84       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)(a) Decision Tree \n",
    "print(\"Decision Tree: \")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "square-young",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        31\n",
      "           1       0.95      0.97      0.96        38\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      0.96      0.98        27\n",
      "           4       0.95      1.00      0.98        41\n",
      "           5       0.97      1.00      0.99        35\n",
      "           6       1.00      0.95      0.97        38\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.94      0.97      0.96        35\n",
      "           9       1.00      0.98      0.99        43\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)(b) Random Forest \n",
    "print(\"Random Forest: \")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "timely-timing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        31\n",
      "           1       0.95      1.00      0.97        38\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       0.96      0.96      0.96        27\n",
      "           4       0.98      0.98      0.98        41\n",
      "           5       1.00      1.00      1.00        35\n",
      "           6       1.00      1.00      1.00        38\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.97      0.94      0.96        35\n",
      "           9       0.98      0.98      0.98        43\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)(c) SVM\n",
    "print(\"SVM: \")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "separated-mistake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        31\n",
      "           1       0.90      0.97      0.94        38\n",
      "           2       0.97      0.97      0.97        38\n",
      "           3       0.93      0.93      0.93        27\n",
      "           4       1.00      0.98      0.99        41\n",
      "           5       0.95      1.00      0.97        35\n",
      "           6       1.00      0.97      0.99        38\n",
      "           7       0.94      1.00      0.97        34\n",
      "           8       0.91      0.91      0.91        35\n",
      "           9       1.00      0.91      0.95        43\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)(d) SGD\n",
    "print(\"SGD: \")\n",
    "print(classification_report(y_test, y_pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "moderate-settlement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        31\n",
      "           1       0.95      0.97      0.96        38\n",
      "           2       1.00      0.97      0.99        38\n",
      "           3       0.96      0.93      0.94        27\n",
      "           4       0.93      1.00      0.96        41\n",
      "           5       0.94      0.97      0.96        35\n",
      "           6       1.00      0.97      0.99        38\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.94      0.94      0.94        35\n",
      "           9       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)(e) Logistic Regression \n",
    "print(\"Logistic Regression: \")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-topic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
